{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/19 15:31:21 WARN Utils: Your hostname, TrungUbun resolves to a loopback address: 127.0.1.1; using 192.168.1.6 instead (on interface enp3s0)\n",
      "23/12/19 15:31:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/19 15:31:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/19 15:31:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "            SparkSession.builder.master(\"local[*]\")\n",
    "            .appName(\"SparkByExamples.com\")\n",
    "            .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "        spark.read.format(\"parquet\")\n",
    "        .options(header=True, inferSchema=False)\n",
    "        .load(\"/home/trung/Downloads/gold_dropoff\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+--------------------+\n",
      "|   Dropoff_datetime|DOLocationID|           DropOffID|\n",
      "+-------------------+------------+--------------------+\n",
      "|2023-01-22 07:49:01|        75.0|Y2023012225769803776|\n",
      "|2023-01-22 07:56:41|       236.0|Y2023012225769803777|\n",
      "|2023-01-22 07:54:23|       143.0|Y2023012225769803778|\n",
      "|2023-01-22 07:56:39|        42.0|Y2023012225769803779|\n",
      "|2023-01-22 07:31:54|        79.0|Y2023012225769803780|\n",
      "|2023-01-22 07:51:12|       144.0|Y2023012225769803781|\n",
      "|2023-01-22 07:06:24|       151.0|Y2023012225769803782|\n",
      "|2023-01-22 07:56:49|        48.0|Y2023012225769803783|\n",
      "|2023-01-22 07:42:28|       262.0|Y2023012225769803784|\n",
      "|2023-01-22 07:52:45|       158.0|Y2023012225769803785|\n",
      "|2023-01-22 07:12:28|       246.0|Y2023012225769803786|\n",
      "|2023-01-22 07:52:17|       143.0|Y2023012225769803787|\n",
      "|2023-01-22 08:04:53|        90.0|Y2023012225769803788|\n",
      "|2023-01-22 07:27:46|        50.0|Y2023012225769803789|\n",
      "|2023-01-22 07:25:06|       151.0|Y2023012225769803790|\n",
      "|2023-01-22 08:27:55|        36.0|Y2023012225769803791|\n",
      "|2023-01-22 07:41:13|       249.0|Y2023012225769803792|\n",
      "|2023-01-22 07:23:02|       142.0|Y2023012225769803793|\n",
      "|2023-01-22 08:04:12|       125.0|Y2023012225769803794|\n",
      "|2023-01-22 07:47:43|       249.0|Y2023012225769803795|\n",
      "+-------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "        spark.read.format(\"parquet\")\n",
    "        .options(header=True, inferSchema=False)\n",
    "        .load(\"/home/trung/Downloads/a/green_tripdata_2023-02.parquet\")\n",
    "    )\n",
    "# count row have tpep_pickup_datetime null\n",
    "print(df.filter(df.lpep_pickup_datetime.isNull()).count())\n",
    "# count row have tpep_dropoff_datetime null\n",
    "print(df.filter(df.lpep_dropoff_datetime.isNull()).count())\n",
    "# count row have PULocationID null\n",
    "print(df.filter(df.PULocationID.isNull()).count())\n",
    "# count row have DOLocationID null\n",
    "print(df.filter(df.DOLocationID.isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2913955"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1110797\n"
     ]
    }
   ],
   "source": [
    "# count row have dispatching_base_num null\n",
    "print(df.filter(df.dispatching_base_num.isNull()).count())\n",
    "# count row have affiliated_base_number null\n",
    "print(df.filter(df.Affiliated_base_number.isNull()).count())\n",
    "# count row have sr_flag null\n",
    "print(df.filter(df.SR_Flag.isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4821\n",
      "0\n",
      "4821\n",
      "4826\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# count row have passenger_count null\n",
    "print(df.filter(df.passenger_count.isNull()).count())\n",
    "# count row have trip_distance null\n",
    "print(df.filter(df.trip_distance.isNull()).count())\n",
    "# count row have store_and_fwd_flag null\n",
    "print(df.filter(df.store_and_fwd_flag.isNull()).count())\n",
    "# count row have trip_type null\n",
    "print(df.filter(df.trip_type.isNull()).count())\n",
    "# count row have VendorID null\n",
    "print(df.filter(df.VendorID.isNull()).count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "passenger count, store_and_fwd_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "4821\n",
      "4821\n",
      "0\n",
      "0\n",
      "0\n",
      "4821\n"
     ]
    }
   ],
   "source": [
    "# count row have fare_amount null\n",
    "print(df.filter(df.fare_amount.isNull()).count())\n",
    "# count row have mta_tax null\n",
    "print(df.filter(df.mta_tax.isNull()).count())\n",
    "# count row have improvement_surcharge null\n",
    "print(df.filter(df.improvement_surcharge.isNull()).count())\n",
    "# count row have payment_type null\n",
    "print(df.filter(df.payment_type.isNull()).count())\n",
    "# count row have RatecodeID null\n",
    "print(df.filter(df.RatecodeID.isNull()).count())\n",
    "# count row have tip_amount null\n",
    "print(df.filter(df.tip_amount.isNull()).count())\n",
    "# count row have tolls_amount null\n",
    "print(df.filter(df.tolls_amount.isNull()).count())\n",
    "# count row have total_amount null\n",
    "print(df.filter(df.total_amount.isNull()).count())\n",
    "# count row have congestion_surcharge null\n",
    "print(df.filter(df.congestion_surcharge.isNull()).count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "payment_type, RatecodeID, congestion_surcharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17273410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2914436"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "        spark.read.format(\"parquet\")\n",
    "        .options(header=True, inferSchema=False)\n",
    "        # .schema(trip_schema)\n",
    "        .load(\"/home/trung/Downloads/gold_pickup\")\n",
    "    )\n",
    "#print count null row in PULocationID\n",
    "print(df.count())\n",
    "df.filter(df.PULocationID.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdo = (\n",
    "    spark.read.format(\"parquet\")\n",
    "    .options(header=True, inferSchema=False)\n",
    "    .load(\"/home/trung/Downloads/gold_dropoff\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+\n",
      "|LocationID|         longitude|          latitude|\n",
      "+----------+------------------+------------------+\n",
      "|         1|-74.17400156582248| 40.69183016020959|\n",
      "|         2|-73.83129979354713| 40.61674619937379|\n",
      "|         3| -73.8474217852696| 40.86447372906584|\n",
      "|         4|-73.97696827424141| 40.72375208451233|\n",
      "|         5|-74.18848459794721| 40.55265878064343|\n",
      "|         6|-74.07177024696533|40.600324409468406|\n",
      "|         7|-73.91969433569462|40.761492617043125|\n",
      "|         8|-73.92308626324494| 40.77855862576789|\n",
      "|         9|-73.78794875477833| 40.75103435668664|\n",
      "|        10|-73.79098676199028| 40.67895308442328|\n",
      "|        11|-74.00748784386448| 40.60427268170344|\n",
      "|        12|-74.01556349991374| 40.70294582144012|\n",
      "|        13|-74.01607927269924|40.712037924667264|\n",
      "|        14|    -74.0298925099| 40.62483367229869|\n",
      "|        15|-73.78597285841018|  40.7833330046879|\n",
      "|        16|-73.77342112932584| 40.76273753216493|\n",
      "|        17|-73.94990480444068| 40.69150702161197|\n",
      "|        18|-73.89018381164814| 40.86768222238494|\n",
      "|        19|-73.72665540152784| 40.73548651046706|\n",
      "|        20|-73.88586744911127|40.857779440562844|\n",
      "+----------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kdvd =(\n",
    "    spark.read.format(\"parquet\")\n",
    "    .options(header=True, inferSchema=False)\n",
    "    .load(\"/home/trung/Downloads/taxi_zones.parquet\")\n",
    ")\n",
    "kdvd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+--------------------+\n",
      "|   Dropoff_datetime|DOLocationID|           DropOffID|\n",
      "+-------------------+------------+--------------------+\n",
      "|2023-01-22 07:49:01|          75|Y2023012225769803776|\n",
      "|2023-01-22 07:56:41|         236|Y2023012225769803777|\n",
      "|2023-01-22 07:54:23|         143|Y2023012225769803778|\n",
      "|2023-01-22 07:56:39|          42|Y2023012225769803779|\n",
      "|2023-01-22 07:31:54|          79|Y2023012225769803780|\n",
      "|2023-01-22 07:51:12|         144|Y2023012225769803781|\n",
      "|2023-01-22 07:06:24|         151|Y2023012225769803782|\n",
      "|2023-01-22 07:56:49|          48|Y2023012225769803783|\n",
      "|2023-01-22 07:42:28|         262|Y2023012225769803784|\n",
      "|2023-01-22 07:52:45|         158|Y2023012225769803785|\n",
      "|2023-01-22 07:12:28|         246|Y2023012225769803786|\n",
      "|2023-01-22 07:52:17|         143|Y2023012225769803787|\n",
      "|2023-01-22 08:04:53|          90|Y2023012225769803788|\n",
      "|2023-01-22 07:27:46|          50|Y2023012225769803789|\n",
      "|2023-01-22 07:25:06|         151|Y2023012225769803790|\n",
      "|2023-01-22 08:27:55|          36|Y2023012225769803791|\n",
      "|2023-01-22 07:41:13|         249|Y2023012225769803792|\n",
      "|2023-01-22 07:23:02|         142|Y2023012225769803793|\n",
      "|2023-01-22 08:04:12|         125|Y2023012225769803794|\n",
      "|2023-01-22 07:47:43|         249|Y2023012225769803795|\n",
      "+-------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gdo.join(kdvd, gdo.DOLocationID == kdvd.LocationID, \"left\").drop(kdvd.LocationID)\n",
    "gdo = gdo.withColumn(\"DOLocationID\", gdo[\"DOLocationID\"].cast(\"int\"))\n",
    "gdo.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
